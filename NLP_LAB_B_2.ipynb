{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDW9vJrt/H60DNK4ZCqMtE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52270-commits/nlp/blob/main/NLP_LAB_B_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNAhOhqkVPER"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_care = \"\"\"This activity focuses on applying preprocessing techniques to sensitive medical or healthcare-related text using Natural Language Processing tools. A simplified medical text corpus, such as PubMed abstracts or curated health articles, is first loaded into a Google Colab environment running Python 3.x with the required libraries NLTK and spaCy installed. The text is then preprocessed by performing sentence and word tokenization using both NLTK and spaCy to break the medical content into structured linguistic units. Further preprocessing includes applying stemming to reduce words to their root forms and lemmatization to convert medical terms into their meaningful dictionary base forms. The outputs of stemming and lemmatization are compared to highlight their differences, showing that stemming may distort medical terms while lemmatization preserves semantic and clinical meaning. This comparison leads to a discussion emphasizing why lemmatization is critical in healthcare NLP, as accurate terminology is essential for tasks such as clinical text analysis, information retrieval, medical coding, and decision support systems. The complete workflow is documented in a Google Colab notebook with proper headings and a discussion section at the end, and the final notebook is submitted as a PDF.\"\"\""
      ],
      "metadata": {
        "id": "Szp8fegeXNAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(health_care)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWOvRNsYbHD2",
        "outputId": "c6f75658-9693-4cc6-da68-74d370f8d978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'activity',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'applying',\n",
              " 'preprocessing',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'sensitive',\n",
              " 'medical',\n",
              " 'or',\n",
              " 'healthcare-related',\n",
              " 'text',\n",
              " 'using',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'tools',\n",
              " '.',\n",
              " 'A',\n",
              " 'simplified',\n",
              " 'medical',\n",
              " 'text',\n",
              " 'corpus',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'PubMed',\n",
              " 'abstracts',\n",
              " 'or',\n",
              " 'curated',\n",
              " 'health',\n",
              " 'articles',\n",
              " ',',\n",
              " 'is',\n",
              " 'first',\n",
              " 'loaded',\n",
              " 'into',\n",
              " 'a',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'environment',\n",
              " 'running',\n",
              " 'Python',\n",
              " '3.x',\n",
              " 'with',\n",
              " 'the',\n",
              " 'required',\n",
              " 'libraries',\n",
              " 'NLTK',\n",
              " 'and',\n",
              " 'spaCy',\n",
              " 'installed',\n",
              " '.',\n",
              " 'The',\n",
              " 'text',\n",
              " 'is',\n",
              " 'then',\n",
              " 'preprocessed',\n",
              " 'by',\n",
              " 'performing',\n",
              " 'sentence',\n",
              " 'and',\n",
              " 'word',\n",
              " 'tokenization',\n",
              " 'using',\n",
              " 'both',\n",
              " 'NLTK',\n",
              " 'and',\n",
              " 'spaCy',\n",
              " 'to',\n",
              " 'break',\n",
              " 'the',\n",
              " 'medical',\n",
              " 'content',\n",
              " 'into',\n",
              " 'structured',\n",
              " 'linguistic',\n",
              " 'units',\n",
              " '.',\n",
              " 'Further',\n",
              " 'preprocessing',\n",
              " 'includes',\n",
              " 'applying',\n",
              " 'stemming',\n",
              " 'to',\n",
              " 'reduce',\n",
              " 'words',\n",
              " 'to',\n",
              " 'their',\n",
              " 'root',\n",
              " 'forms',\n",
              " 'and',\n",
              " 'lemmatization',\n",
              " 'to',\n",
              " 'convert',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'into',\n",
              " 'their',\n",
              " 'meaningful',\n",
              " 'dictionary',\n",
              " 'base',\n",
              " 'forms',\n",
              " '.',\n",
              " 'The',\n",
              " 'outputs',\n",
              " 'of',\n",
              " 'stemming',\n",
              " 'and',\n",
              " 'lemmatization',\n",
              " 'are',\n",
              " 'compared',\n",
              " 'to',\n",
              " 'highlight',\n",
              " 'their',\n",
              " 'differences',\n",
              " ',',\n",
              " 'showing',\n",
              " 'that',\n",
              " 'stemming',\n",
              " 'may',\n",
              " 'distort',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'while',\n",
              " 'lemmatization',\n",
              " 'preserves',\n",
              " 'semantic',\n",
              " 'and',\n",
              " 'clinical',\n",
              " 'meaning',\n",
              " '.',\n",
              " 'This',\n",
              " 'comparison',\n",
              " 'leads',\n",
              " 'to',\n",
              " 'a',\n",
              " 'discussion',\n",
              " 'emphasizing',\n",
              " 'why',\n",
              " 'lemmatization',\n",
              " 'is',\n",
              " 'critical',\n",
              " 'in',\n",
              " 'healthcare',\n",
              " 'NLP',\n",
              " ',',\n",
              " 'as',\n",
              " 'accurate',\n",
              " 'terminology',\n",
              " 'is',\n",
              " 'essential',\n",
              " 'for',\n",
              " 'tasks',\n",
              " 'such',\n",
              " 'as',\n",
              " 'clinical',\n",
              " 'text',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " ',',\n",
              " 'medical',\n",
              " 'coding',\n",
              " ',',\n",
              " 'and',\n",
              " 'decision',\n",
              " 'support',\n",
              " 'systems',\n",
              " '.',\n",
              " 'The',\n",
              " 'complete',\n",
              " 'workflow',\n",
              " 'is',\n",
              " 'documented',\n",
              " 'in',\n",
              " 'a',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'notebook',\n",
              " 'with',\n",
              " 'proper',\n",
              " 'headings',\n",
              " 'and',\n",
              " 'a',\n",
              " 'discussion',\n",
              " 'section',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'final',\n",
              " 'notebook',\n",
              " 'is',\n",
              " 'submitted',\n",
              " 'as',\n",
              " 'a',\n",
              " 'PDF',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(health_care)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-nfW3V1c2ZR",
        "outputId": "0ecf1468-59bc-46d2-bee8-8820ab1d0dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This activity focuses on applying preprocessing techniques to sensitive medical or healthcare-related text using Natural Language Processing tools.',\n",
              " 'A simplified medical text corpus, such as PubMed abstracts or curated health articles, is first loaded into a Google Colab environment running Python 3.x with the required libraries NLTK and spaCy installed.',\n",
              " 'The text is then preprocessed by performing sentence and word tokenization using both NLTK and spaCy to break the medical content into structured linguistic units.',\n",
              " 'Further preprocessing includes applying stemming to reduce words to their root forms and lemmatization to convert medical terms into their meaningful dictionary base forms.',\n",
              " 'The outputs of stemming and lemmatization are compared to highlight their differences, showing that stemming may distort medical terms while lemmatization preserves semantic and clinical meaning.',\n",
              " 'This comparison leads to a discussion emphasizing why lemmatization is critical in healthcare NLP, as accurate terminology is essential for tasks such as clinical text analysis, information retrieval, medical coding, and decision support systems.',\n",
              " 'The complete workflow is documented in a Google Colab notebook with proper headings and a discussion section at the end, and the final notebook is submitted as a PDF.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca2tC9hwddrW",
        "outputId": "1e6114bf-ea87-45bb-826a-c16c046f4318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize (health_care)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEfIp5Nwd1rY",
        "outputId": "47df63b9-b78b-4e92-b1cc-5b2e4ab3d1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'activity',\n",
              " 'focuses',\n",
              " 'on',\n",
              " 'applying',\n",
              " 'preprocessing',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'sensitive',\n",
              " 'medical',\n",
              " 'or',\n",
              " 'healthcare-related',\n",
              " 'text',\n",
              " 'using',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'tools',\n",
              " '.',\n",
              " 'A',\n",
              " 'simplified',\n",
              " 'medical',\n",
              " 'text',\n",
              " 'corpus',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'PubMed',\n",
              " 'abstracts',\n",
              " 'or',\n",
              " 'curated',\n",
              " 'health',\n",
              " 'articles',\n",
              " ',',\n",
              " 'is',\n",
              " 'first',\n",
              " 'loaded',\n",
              " 'into',\n",
              " 'a',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'environment',\n",
              " 'running',\n",
              " 'Python',\n",
              " '3.x',\n",
              " 'with',\n",
              " 'the',\n",
              " 'required',\n",
              " 'libraries',\n",
              " 'NLTK',\n",
              " 'and',\n",
              " 'spaCy',\n",
              " 'installed',\n",
              " '.',\n",
              " 'The',\n",
              " 'text',\n",
              " 'is',\n",
              " 'then',\n",
              " 'preprocessed',\n",
              " 'by',\n",
              " 'performing',\n",
              " 'sentence',\n",
              " 'and',\n",
              " 'word',\n",
              " 'tokenization',\n",
              " 'using',\n",
              " 'both',\n",
              " 'NLTK',\n",
              " 'and',\n",
              " 'spaCy',\n",
              " 'to',\n",
              " 'break',\n",
              " 'the',\n",
              " 'medical',\n",
              " 'content',\n",
              " 'into',\n",
              " 'structured',\n",
              " 'linguistic',\n",
              " 'units',\n",
              " '.',\n",
              " 'Further',\n",
              " 'preprocessing',\n",
              " 'includes',\n",
              " 'applying',\n",
              " 'stemming',\n",
              " 'to',\n",
              " 'reduce',\n",
              " 'words',\n",
              " 'to',\n",
              " 'their',\n",
              " 'root',\n",
              " 'forms',\n",
              " 'and',\n",
              " 'lemmatization',\n",
              " 'to',\n",
              " 'convert',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'into',\n",
              " 'their',\n",
              " 'meaningful',\n",
              " 'dictionary',\n",
              " 'base',\n",
              " 'forms',\n",
              " '.',\n",
              " 'The',\n",
              " 'outputs',\n",
              " 'of',\n",
              " 'stemming',\n",
              " 'and',\n",
              " 'lemmatization',\n",
              " 'are',\n",
              " 'compared',\n",
              " 'to',\n",
              " 'highlight',\n",
              " 'their',\n",
              " 'differences',\n",
              " ',',\n",
              " 'showing',\n",
              " 'that',\n",
              " 'stemming',\n",
              " 'may',\n",
              " 'distort',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'while',\n",
              " 'lemmatization',\n",
              " 'preserves',\n",
              " 'semantic',\n",
              " 'and',\n",
              " 'clinical',\n",
              " 'meaning',\n",
              " '.',\n",
              " 'This',\n",
              " 'comparison',\n",
              " 'leads',\n",
              " 'to',\n",
              " 'a',\n",
              " 'discussion',\n",
              " 'emphasizing',\n",
              " 'why',\n",
              " 'lemmatization',\n",
              " 'is',\n",
              " 'critical',\n",
              " 'in',\n",
              " 'healthcare',\n",
              " 'NLP',\n",
              " ',',\n",
              " 'as',\n",
              " 'accurate',\n",
              " 'terminology',\n",
              " 'is',\n",
              " 'essential',\n",
              " 'for',\n",
              " 'tasks',\n",
              " 'such',\n",
              " 'as',\n",
              " 'clinical',\n",
              " 'text',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " ',',\n",
              " 'medical',\n",
              " 'coding',\n",
              " ',',\n",
              " 'and',\n",
              " 'decision',\n",
              " 'support',\n",
              " 'systems',\n",
              " '.',\n",
              " 'The',\n",
              " 'complete',\n",
              " 'workflow',\n",
              " 'is',\n",
              " 'documented',\n",
              " 'in',\n",
              " 'a',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'notebook',\n",
              " 'with',\n",
              " 'proper',\n",
              " 'headings',\n",
              " 'and',\n",
              " 'a',\n",
              " 'discussion',\n",
              " 'section',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'final',\n",
              " 'notebook',\n",
              " 'is',\n",
              " 'submitted',\n",
              " 'as',\n",
              " 'a',\n",
              " 'PDF',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_care = \"\"\"This activity focuses on applying preprocessing techniques to sensitive medical or healthcare-related text using Natural Language Processing tools. A simplified medical text corpus, such as PubMed abstracts or curated health articles, is first loaded into a Google Colab environment running Python 3.x with the required libraries NLTK and spaCy installed. The text is then preprocessed by performing sentence and word tokenization using both NLTK and spaCy to break the medical content into structured linguistic units. Further preprocessing includes applying stemming to reduce words to their root forms and lemmatization to convert medical terms into their meaningful dictionary base forms. The outputs of stemming and lemmatization are compared to highlight their differences, showing that stemming may distort medical terms while lemmatization preserves semantic and clinical meaning. This comparison leads to a discussion emphasizing why lemmatization is critical in healthcare NLP, as accurate terminology is essential for tasks such as clinical text analysis, information retrieval, medical coding, and decision support systems. The complete workflow is documented in a Google Colab notebook with proper headings and a discussion section at the end, and the final notebook is submitted as a PDF.\"\"\"\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "words_in_quote = word_tokenize(health_care)\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "    if word.casefold() not in stop_words:\n",
        "        filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y5i8JvhfYkM",
        "outputId": "0141a0da-2e92-4baf-a870-8bb360528b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['activity',\n",
              " 'focuses',\n",
              " 'applying',\n",
              " 'preprocessing',\n",
              " 'techniques',\n",
              " 'sensitive',\n",
              " 'medical',\n",
              " 'healthcare-related',\n",
              " 'text',\n",
              " 'using',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'tools',\n",
              " '.',\n",
              " 'simplified',\n",
              " 'medical',\n",
              " 'text',\n",
              " 'corpus',\n",
              " ',',\n",
              " 'PubMed',\n",
              " 'abstracts',\n",
              " 'curated',\n",
              " 'health',\n",
              " 'articles',\n",
              " ',',\n",
              " 'first',\n",
              " 'loaded',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'environment',\n",
              " 'running',\n",
              " 'Python',\n",
              " '3.x',\n",
              " 'required',\n",
              " 'libraries',\n",
              " 'NLTK',\n",
              " 'spaCy',\n",
              " 'installed',\n",
              " '.',\n",
              " 'text',\n",
              " 'preprocessed',\n",
              " 'performing',\n",
              " 'sentence',\n",
              " 'word',\n",
              " 'tokenization',\n",
              " 'using',\n",
              " 'NLTK',\n",
              " 'spaCy',\n",
              " 'break',\n",
              " 'medical',\n",
              " 'content',\n",
              " 'structured',\n",
              " 'linguistic',\n",
              " 'units',\n",
              " '.',\n",
              " 'preprocessing',\n",
              " 'includes',\n",
              " 'applying',\n",
              " 'stemming',\n",
              " 'reduce',\n",
              " 'words',\n",
              " 'root',\n",
              " 'forms',\n",
              " 'lemmatization',\n",
              " 'convert',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'meaningful',\n",
              " 'dictionary',\n",
              " 'base',\n",
              " 'forms',\n",
              " '.',\n",
              " 'outputs',\n",
              " 'stemming',\n",
              " 'lemmatization',\n",
              " 'compared',\n",
              " 'highlight',\n",
              " 'differences',\n",
              " ',',\n",
              " 'showing',\n",
              " 'stemming',\n",
              " 'may',\n",
              " 'distort',\n",
              " 'medical',\n",
              " 'terms',\n",
              " 'lemmatization',\n",
              " 'preserves',\n",
              " 'semantic',\n",
              " 'clinical',\n",
              " 'meaning',\n",
              " '.',\n",
              " 'comparison',\n",
              " 'leads',\n",
              " 'discussion',\n",
              " 'emphasizing',\n",
              " 'lemmatization',\n",
              " 'critical',\n",
              " 'healthcare',\n",
              " 'NLP',\n",
              " ',',\n",
              " 'accurate',\n",
              " 'terminology',\n",
              " 'essential',\n",
              " 'tasks',\n",
              " 'clinical',\n",
              " 'text',\n",
              " 'analysis',\n",
              " ',',\n",
              " 'information',\n",
              " 'retrieval',\n",
              " ',',\n",
              " 'medical',\n",
              " 'coding',\n",
              " ',',\n",
              " 'decision',\n",
              " 'support',\n",
              " 'systems',\n",
              " '.',\n",
              " 'complete',\n",
              " 'workflow',\n",
              " 'documented',\n",
              " 'Google',\n",
              " 'Colab',\n",
              " 'notebook',\n",
              " 'proper',\n",
              " 'headings',\n",
              " 'discussion',\n",
              " 'section',\n",
              " 'end',\n",
              " ',',\n",
              " 'final',\n",
              " 'notebook',\n",
              " 'submitted',\n",
              " 'PDF',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(health_care)\n",
        "stemmed = [stemmer.stem(word) for word in words]\n",
        "stemmed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4cnTwJjgPAj",
        "outputId": "819f967f-ed1e-4303-fc51-8a7b5451a0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thi',\n",
              " 'activ',\n",
              " 'focus',\n",
              " 'on',\n",
              " 'appli',\n",
              " 'preprocess',\n",
              " 'techniqu',\n",
              " 'to',\n",
              " 'sensit',\n",
              " 'medic',\n",
              " 'or',\n",
              " 'healthcare-rel',\n",
              " 'text',\n",
              " 'use',\n",
              " 'natur',\n",
              " 'languag',\n",
              " 'process',\n",
              " 'tool',\n",
              " '.',\n",
              " 'a',\n",
              " 'simplifi',\n",
              " 'medic',\n",
              " 'text',\n",
              " 'corpu',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'pubm',\n",
              " 'abstract',\n",
              " 'or',\n",
              " 'curat',\n",
              " 'health',\n",
              " 'articl',\n",
              " ',',\n",
              " 'is',\n",
              " 'first',\n",
              " 'load',\n",
              " 'into',\n",
              " 'a',\n",
              " 'googl',\n",
              " 'colab',\n",
              " 'environ',\n",
              " 'run',\n",
              " 'python',\n",
              " '3.x',\n",
              " 'with',\n",
              " 'the',\n",
              " 'requir',\n",
              " 'librari',\n",
              " 'nltk',\n",
              " 'and',\n",
              " 'spaci',\n",
              " 'instal',\n",
              " '.',\n",
              " 'the',\n",
              " 'text',\n",
              " 'is',\n",
              " 'then',\n",
              " 'preprocess',\n",
              " 'by',\n",
              " 'perform',\n",
              " 'sentenc',\n",
              " 'and',\n",
              " 'word',\n",
              " 'token',\n",
              " 'use',\n",
              " 'both',\n",
              " 'nltk',\n",
              " 'and',\n",
              " 'spaci',\n",
              " 'to',\n",
              " 'break',\n",
              " 'the',\n",
              " 'medic',\n",
              " 'content',\n",
              " 'into',\n",
              " 'structur',\n",
              " 'linguist',\n",
              " 'unit',\n",
              " '.',\n",
              " 'further',\n",
              " 'preprocess',\n",
              " 'includ',\n",
              " 'appli',\n",
              " 'stem',\n",
              " 'to',\n",
              " 'reduc',\n",
              " 'word',\n",
              " 'to',\n",
              " 'their',\n",
              " 'root',\n",
              " 'form',\n",
              " 'and',\n",
              " 'lemmat',\n",
              " 'to',\n",
              " 'convert',\n",
              " 'medic',\n",
              " 'term',\n",
              " 'into',\n",
              " 'their',\n",
              " 'meaning',\n",
              " 'dictionari',\n",
              " 'base',\n",
              " 'form',\n",
              " '.',\n",
              " 'the',\n",
              " 'output',\n",
              " 'of',\n",
              " 'stem',\n",
              " 'and',\n",
              " 'lemmat',\n",
              " 'are',\n",
              " 'compar',\n",
              " 'to',\n",
              " 'highlight',\n",
              " 'their',\n",
              " 'differ',\n",
              " ',',\n",
              " 'show',\n",
              " 'that',\n",
              " 'stem',\n",
              " 'may',\n",
              " 'distort',\n",
              " 'medic',\n",
              " 'term',\n",
              " 'while',\n",
              " 'lemmat',\n",
              " 'preserv',\n",
              " 'semant',\n",
              " 'and',\n",
              " 'clinic',\n",
              " 'mean',\n",
              " '.',\n",
              " 'thi',\n",
              " 'comparison',\n",
              " 'lead',\n",
              " 'to',\n",
              " 'a',\n",
              " 'discuss',\n",
              " 'emphas',\n",
              " 'whi',\n",
              " 'lemmat',\n",
              " 'is',\n",
              " 'critic',\n",
              " 'in',\n",
              " 'healthcar',\n",
              " 'nlp',\n",
              " ',',\n",
              " 'as',\n",
              " 'accur',\n",
              " 'terminolog',\n",
              " 'is',\n",
              " 'essenti',\n",
              " 'for',\n",
              " 'task',\n",
              " 'such',\n",
              " 'as',\n",
              " 'clinic',\n",
              " 'text',\n",
              " 'analysi',\n",
              " ',',\n",
              " 'inform',\n",
              " 'retriev',\n",
              " ',',\n",
              " 'medic',\n",
              " 'code',\n",
              " ',',\n",
              " 'and',\n",
              " 'decis',\n",
              " 'support',\n",
              " 'system',\n",
              " '.',\n",
              " 'the',\n",
              " 'complet',\n",
              " 'workflow',\n",
              " 'is',\n",
              " 'document',\n",
              " 'in',\n",
              " 'a',\n",
              " 'googl',\n",
              " 'colab',\n",
              " 'notebook',\n",
              " 'with',\n",
              " 'proper',\n",
              " 'head',\n",
              " 'and',\n",
              " 'a',\n",
              " 'discuss',\n",
              " 'section',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'final',\n",
              " 'notebook',\n",
              " 'is',\n",
              " 'submit',\n",
              " 'as',\n",
              " 'a',\n",
              " 'pdf',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d42ee1e5",
        "outputId": "c9049363-0dec-419e-f732-b33eaaf53a22"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "health_care = \"\"\"This activity focuses on applying preprocessing techniques to sensitive medical or healthcare-related text using Natural Language Processing tools. A simplified medical text corpus, such as PubMed abstracts or curated health articles, is first loaded into a Google Colab environment running Python 3.x with the required libraries NLTK and spaCy installed. The text is then preprocessed by performing sentence and word tokenization using both NLTK and spaCy to break the medical content into structured linguistic units. Further preprocessing includes applying stemming to reduce words to their root forms and lemmatization to convert medical terms into their meaningful dictionary base forms. The outputs of stemming and lemmatization are compared to highlight their differences, showing that stemming may distort medical terms while lemmatization preserves semantic and clinical meaning. This comparison leads to a discussion emphasizing why lemmatization is critical in healthcare NLP, as accurate terminology is essential for tasks such as clinical text analysis, information retrieval, medical coding, and decision support systems. The complete workflow is documented in a Google Colab notebook with proper headings and a discussion section at the end, and the final notebook is submitted as a PDF.\"\"\"\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "snowball = SnowballStemmer('english')\n",
        "words = word_tokenize(health_care)\n",
        "for word in words:\n",
        "  print(word,\"---->\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This ---->\n",
            "activity ---->\n",
            "focuses ---->\n",
            "on ---->\n",
            "applying ---->\n",
            "preprocessing ---->\n",
            "techniques ---->\n",
            "to ---->\n",
            "sensitive ---->\n",
            "medical ---->\n",
            "or ---->\n",
            "healthcare-related ---->\n",
            "text ---->\n",
            "using ---->\n",
            "Natural ---->\n",
            "Language ---->\n",
            "Processing ---->\n",
            "tools ---->\n",
            ". ---->\n",
            "A ---->\n",
            "simplified ---->\n",
            "medical ---->\n",
            "text ---->\n",
            "corpus ---->\n",
            ", ---->\n",
            "such ---->\n",
            "as ---->\n",
            "PubMed ---->\n",
            "abstracts ---->\n",
            "or ---->\n",
            "curated ---->\n",
            "health ---->\n",
            "articles ---->\n",
            ", ---->\n",
            "is ---->\n",
            "first ---->\n",
            "loaded ---->\n",
            "into ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "environment ---->\n",
            "running ---->\n",
            "Python ---->\n",
            "3.x ---->\n",
            "with ---->\n",
            "the ---->\n",
            "required ---->\n",
            "libraries ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "installed ---->\n",
            ". ---->\n",
            "The ---->\n",
            "text ---->\n",
            "is ---->\n",
            "then ---->\n",
            "preprocessed ---->\n",
            "by ---->\n",
            "performing ---->\n",
            "sentence ---->\n",
            "and ---->\n",
            "word ---->\n",
            "tokenization ---->\n",
            "using ---->\n",
            "both ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "to ---->\n",
            "break ---->\n",
            "the ---->\n",
            "medical ---->\n",
            "content ---->\n",
            "into ---->\n",
            "structured ---->\n",
            "linguistic ---->\n",
            "units ---->\n",
            ". ---->\n",
            "Further ---->\n",
            "preprocessing ---->\n",
            "includes ---->\n",
            "applying ---->\n",
            "stemming ---->\n",
            "to ---->\n",
            "reduce ---->\n",
            "words ---->\n",
            "to ---->\n",
            "their ---->\n",
            "root ---->\n",
            "forms ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "to ---->\n",
            "convert ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "into ---->\n",
            "their ---->\n",
            "meaningful ---->\n",
            "dictionary ---->\n",
            "base ---->\n",
            "forms ---->\n",
            ". ---->\n",
            "The ---->\n",
            "outputs ---->\n",
            "of ---->\n",
            "stemming ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "are ---->\n",
            "compared ---->\n",
            "to ---->\n",
            "highlight ---->\n",
            "their ---->\n",
            "differences ---->\n",
            ", ---->\n",
            "showing ---->\n",
            "that ---->\n",
            "stemming ---->\n",
            "may ---->\n",
            "distort ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "while ---->\n",
            "lemmatization ---->\n",
            "preserves ---->\n",
            "semantic ---->\n",
            "and ---->\n",
            "clinical ---->\n",
            "meaning ---->\n",
            ". ---->\n",
            "This ---->\n",
            "comparison ---->\n",
            "leads ---->\n",
            "to ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "emphasizing ---->\n",
            "why ---->\n",
            "lemmatization ---->\n",
            "is ---->\n",
            "critical ---->\n",
            "in ---->\n",
            "healthcare ---->\n",
            "NLP ---->\n",
            ", ---->\n",
            "as ---->\n",
            "accurate ---->\n",
            "terminology ---->\n",
            "is ---->\n",
            "essential ---->\n",
            "for ---->\n",
            "tasks ---->\n",
            "such ---->\n",
            "as ---->\n",
            "clinical ---->\n",
            "text ---->\n",
            "analysis ---->\n",
            ", ---->\n",
            "information ---->\n",
            "retrieval ---->\n",
            ", ---->\n",
            "medical ---->\n",
            "coding ---->\n",
            ", ---->\n",
            "and ---->\n",
            "decision ---->\n",
            "support ---->\n",
            "systems ---->\n",
            ". ---->\n",
            "The ---->\n",
            "complete ---->\n",
            "workflow ---->\n",
            "is ---->\n",
            "documented ---->\n",
            "in ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "notebook ---->\n",
            "with ---->\n",
            "proper ---->\n",
            "headings ---->\n",
            "and ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "section ---->\n",
            "at ---->\n",
            "the ---->\n",
            "end ---->\n",
            ", ---->\n",
            "and ---->\n",
            "the ---->\n",
            "final ---->\n",
            "notebook ---->\n",
            "is ---->\n",
            "submitted ---->\n",
            "as ---->\n",
            "a ---->\n",
            "PDF ---->\n",
            ". ---->\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "lancaster = LancasterStemmer()\n",
        "words = word_tokenize(health_care)\n",
        "for word in words:\n",
        "  print(word,\"---->\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpFsPmEfikQp",
        "outputId": "b406af89-8c40-4767-a64a-98240299a807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This ---->\n",
            "activity ---->\n",
            "focuses ---->\n",
            "on ---->\n",
            "applying ---->\n",
            "preprocessing ---->\n",
            "techniques ---->\n",
            "to ---->\n",
            "sensitive ---->\n",
            "medical ---->\n",
            "or ---->\n",
            "healthcare-related ---->\n",
            "text ---->\n",
            "using ---->\n",
            "Natural ---->\n",
            "Language ---->\n",
            "Processing ---->\n",
            "tools ---->\n",
            ". ---->\n",
            "A ---->\n",
            "simplified ---->\n",
            "medical ---->\n",
            "text ---->\n",
            "corpus ---->\n",
            ", ---->\n",
            "such ---->\n",
            "as ---->\n",
            "PubMed ---->\n",
            "abstracts ---->\n",
            "or ---->\n",
            "curated ---->\n",
            "health ---->\n",
            "articles ---->\n",
            ", ---->\n",
            "is ---->\n",
            "first ---->\n",
            "loaded ---->\n",
            "into ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "environment ---->\n",
            "running ---->\n",
            "Python ---->\n",
            "3.x ---->\n",
            "with ---->\n",
            "the ---->\n",
            "required ---->\n",
            "libraries ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "installed ---->\n",
            ". ---->\n",
            "The ---->\n",
            "text ---->\n",
            "is ---->\n",
            "then ---->\n",
            "preprocessed ---->\n",
            "by ---->\n",
            "performing ---->\n",
            "sentence ---->\n",
            "and ---->\n",
            "word ---->\n",
            "tokenization ---->\n",
            "using ---->\n",
            "both ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "to ---->\n",
            "break ---->\n",
            "the ---->\n",
            "medical ---->\n",
            "content ---->\n",
            "into ---->\n",
            "structured ---->\n",
            "linguistic ---->\n",
            "units ---->\n",
            ". ---->\n",
            "Further ---->\n",
            "preprocessing ---->\n",
            "includes ---->\n",
            "applying ---->\n",
            "stemming ---->\n",
            "to ---->\n",
            "reduce ---->\n",
            "words ---->\n",
            "to ---->\n",
            "their ---->\n",
            "root ---->\n",
            "forms ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "to ---->\n",
            "convert ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "into ---->\n",
            "their ---->\n",
            "meaningful ---->\n",
            "dictionary ---->\n",
            "base ---->\n",
            "forms ---->\n",
            ". ---->\n",
            "The ---->\n",
            "outputs ---->\n",
            "of ---->\n",
            "stemming ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "are ---->\n",
            "compared ---->\n",
            "to ---->\n",
            "highlight ---->\n",
            "their ---->\n",
            "differences ---->\n",
            ", ---->\n",
            "showing ---->\n",
            "that ---->\n",
            "stemming ---->\n",
            "may ---->\n",
            "distort ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "while ---->\n",
            "lemmatization ---->\n",
            "preserves ---->\n",
            "semantic ---->\n",
            "and ---->\n",
            "clinical ---->\n",
            "meaning ---->\n",
            ". ---->\n",
            "This ---->\n",
            "comparison ---->\n",
            "leads ---->\n",
            "to ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "emphasizing ---->\n",
            "why ---->\n",
            "lemmatization ---->\n",
            "is ---->\n",
            "critical ---->\n",
            "in ---->\n",
            "healthcare ---->\n",
            "NLP ---->\n",
            ", ---->\n",
            "as ---->\n",
            "accurate ---->\n",
            "terminology ---->\n",
            "is ---->\n",
            "essential ---->\n",
            "for ---->\n",
            "tasks ---->\n",
            "such ---->\n",
            "as ---->\n",
            "clinical ---->\n",
            "text ---->\n",
            "analysis ---->\n",
            ", ---->\n",
            "information ---->\n",
            "retrieval ---->\n",
            ", ---->\n",
            "medical ---->\n",
            "coding ---->\n",
            ", ---->\n",
            "and ---->\n",
            "decision ---->\n",
            "support ---->\n",
            "systems ---->\n",
            ". ---->\n",
            "The ---->\n",
            "complete ---->\n",
            "workflow ---->\n",
            "is ---->\n",
            "documented ---->\n",
            "in ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "notebook ---->\n",
            "with ---->\n",
            "proper ---->\n",
            "headings ---->\n",
            "and ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "section ---->\n",
            "at ---->\n",
            "the ---->\n",
            "end ---->\n",
            ", ---->\n",
            "and ---->\n",
            "the ---->\n",
            "final ---->\n",
            "notebook ---->\n",
            "is ---->\n",
            "submitted ---->\n",
            "as ---->\n",
            "a ---->\n",
            "PDF ---->\n",
            ". ---->\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = word_tokenize(health_care)\n",
        "for word in words:\n",
        "  print(word,\"---->\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3NeDlg2i5DK",
        "outputId": "d5fc2f40-fa02-4ca6-e9f5-50d026c6872b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This ---->\n",
            "activity ---->\n",
            "focuses ---->\n",
            "on ---->\n",
            "applying ---->\n",
            "preprocessing ---->\n",
            "techniques ---->\n",
            "to ---->\n",
            "sensitive ---->\n",
            "medical ---->\n",
            "or ---->\n",
            "healthcare-related ---->\n",
            "text ---->\n",
            "using ---->\n",
            "Natural ---->\n",
            "Language ---->\n",
            "Processing ---->\n",
            "tools ---->\n",
            ". ---->\n",
            "A ---->\n",
            "simplified ---->\n",
            "medical ---->\n",
            "text ---->\n",
            "corpus ---->\n",
            ", ---->\n",
            "such ---->\n",
            "as ---->\n",
            "PubMed ---->\n",
            "abstracts ---->\n",
            "or ---->\n",
            "curated ---->\n",
            "health ---->\n",
            "articles ---->\n",
            ", ---->\n",
            "is ---->\n",
            "first ---->\n",
            "loaded ---->\n",
            "into ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "environment ---->\n",
            "running ---->\n",
            "Python ---->\n",
            "3.x ---->\n",
            "with ---->\n",
            "the ---->\n",
            "required ---->\n",
            "libraries ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "installed ---->\n",
            ". ---->\n",
            "The ---->\n",
            "text ---->\n",
            "is ---->\n",
            "then ---->\n",
            "preprocessed ---->\n",
            "by ---->\n",
            "performing ---->\n",
            "sentence ---->\n",
            "and ---->\n",
            "word ---->\n",
            "tokenization ---->\n",
            "using ---->\n",
            "both ---->\n",
            "NLTK ---->\n",
            "and ---->\n",
            "spaCy ---->\n",
            "to ---->\n",
            "break ---->\n",
            "the ---->\n",
            "medical ---->\n",
            "content ---->\n",
            "into ---->\n",
            "structured ---->\n",
            "linguistic ---->\n",
            "units ---->\n",
            ". ---->\n",
            "Further ---->\n",
            "preprocessing ---->\n",
            "includes ---->\n",
            "applying ---->\n",
            "stemming ---->\n",
            "to ---->\n",
            "reduce ---->\n",
            "words ---->\n",
            "to ---->\n",
            "their ---->\n",
            "root ---->\n",
            "forms ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "to ---->\n",
            "convert ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "into ---->\n",
            "their ---->\n",
            "meaningful ---->\n",
            "dictionary ---->\n",
            "base ---->\n",
            "forms ---->\n",
            ". ---->\n",
            "The ---->\n",
            "outputs ---->\n",
            "of ---->\n",
            "stemming ---->\n",
            "and ---->\n",
            "lemmatization ---->\n",
            "are ---->\n",
            "compared ---->\n",
            "to ---->\n",
            "highlight ---->\n",
            "their ---->\n",
            "differences ---->\n",
            ", ---->\n",
            "showing ---->\n",
            "that ---->\n",
            "stemming ---->\n",
            "may ---->\n",
            "distort ---->\n",
            "medical ---->\n",
            "terms ---->\n",
            "while ---->\n",
            "lemmatization ---->\n",
            "preserves ---->\n",
            "semantic ---->\n",
            "and ---->\n",
            "clinical ---->\n",
            "meaning ---->\n",
            ". ---->\n",
            "This ---->\n",
            "comparison ---->\n",
            "leads ---->\n",
            "to ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "emphasizing ---->\n",
            "why ---->\n",
            "lemmatization ---->\n",
            "is ---->\n",
            "critical ---->\n",
            "in ---->\n",
            "healthcare ---->\n",
            "NLP ---->\n",
            ", ---->\n",
            "as ---->\n",
            "accurate ---->\n",
            "terminology ---->\n",
            "is ---->\n",
            "essential ---->\n",
            "for ---->\n",
            "tasks ---->\n",
            "such ---->\n",
            "as ---->\n",
            "clinical ---->\n",
            "text ---->\n",
            "analysis ---->\n",
            ", ---->\n",
            "information ---->\n",
            "retrieval ---->\n",
            ", ---->\n",
            "medical ---->\n",
            "coding ---->\n",
            ", ---->\n",
            "and ---->\n",
            "decision ---->\n",
            "support ---->\n",
            "systems ---->\n",
            ". ---->\n",
            "The ---->\n",
            "complete ---->\n",
            "workflow ---->\n",
            "is ---->\n",
            "documented ---->\n",
            "in ---->\n",
            "a ---->\n",
            "Google ---->\n",
            "Colab ---->\n",
            "notebook ---->\n",
            "with ---->\n",
            "proper ---->\n",
            "headings ---->\n",
            "and ---->\n",
            "a ---->\n",
            "discussion ---->\n",
            "section ---->\n",
            "at ---->\n",
            "the ---->\n",
            "end ---->\n",
            ", ---->\n",
            "and ---->\n",
            "the ---->\n",
            "final ---->\n",
            "notebook ---->\n",
            "is ---->\n",
            "submitted ---->\n",
            "as ---->\n",
            "a ---->\n",
            "PDF ---->\n",
            ". ---->\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_care = \"\"\"This activity focuses on applying preprocessing techniques to sensitive medical or healthcare-related text using Natural Language Processing tools. A simplified medical text corpus, such as PubMed abstracts or curated health articles, is first loaded into a Google Colab environment running Python 3.x with the required libraries NLTK and spaCy installed. The text is then preprocessed by performing sentence and word tokenization using both NLTK and spaCy to break the medical content into structured linguistic units. Further preprocessing includes applying stemming to reduce words to their root forms and lemmatization to convert medical terms into their meaningful dictionary base forms. The outputs of stemming and lemmatization are compared to highlight their differences, showing that stemming may distort medical terms while lemmatization preserves semantic and clinical meaning. This comparison leads to a discussion emphasizing why lemmatization is critical in healthcare NLP, as accurate terminology is essential for tasks such as clinical text analysis, information retrieval, medical coding, and decision support systems. The complete workflow is documented in a Google Colab notebook with proper headings and a discussion section at the end, and the final notebook is submitted as a PDF.\"\"\"\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(health_care)\n",
        "for word in words:\n",
        "  print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh135Kc3jMCk",
        "outputId": "4502fbfc-5e59-4562-e87a-8046d49e1adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This\n",
            "activity\n",
            "focus\n",
            "on\n",
            "applying\n",
            "preprocessing\n",
            "technique\n",
            "to\n",
            "sensitive\n",
            "medical\n",
            "or\n",
            "healthcare-related\n",
            "text\n",
            "using\n",
            "Natural\n",
            "Language\n",
            "Processing\n",
            "tool\n",
            ".\n",
            "A\n",
            "simplified\n",
            "medical\n",
            "text\n",
            "corpus\n",
            ",\n",
            "such\n",
            "a\n",
            "PubMed\n",
            "abstract\n",
            "or\n",
            "curated\n",
            "health\n",
            "article\n",
            ",\n",
            "is\n",
            "first\n",
            "loaded\n",
            "into\n",
            "a\n",
            "Google\n",
            "Colab\n",
            "environment\n",
            "running\n",
            "Python\n",
            "3.x\n",
            "with\n",
            "the\n",
            "required\n",
            "library\n",
            "NLTK\n",
            "and\n",
            "spaCy\n",
            "installed\n",
            ".\n",
            "The\n",
            "text\n",
            "is\n",
            "then\n",
            "preprocessed\n",
            "by\n",
            "performing\n",
            "sentence\n",
            "and\n",
            "word\n",
            "tokenization\n",
            "using\n",
            "both\n",
            "NLTK\n",
            "and\n",
            "spaCy\n",
            "to\n",
            "break\n",
            "the\n",
            "medical\n",
            "content\n",
            "into\n",
            "structured\n",
            "linguistic\n",
            "unit\n",
            ".\n",
            "Further\n",
            "preprocessing\n",
            "includes\n",
            "applying\n",
            "stemming\n",
            "to\n",
            "reduce\n",
            "word\n",
            "to\n",
            "their\n",
            "root\n",
            "form\n",
            "and\n",
            "lemmatization\n",
            "to\n",
            "convert\n",
            "medical\n",
            "term\n",
            "into\n",
            "their\n",
            "meaningful\n",
            "dictionary\n",
            "base\n",
            "form\n",
            ".\n",
            "The\n",
            "output\n",
            "of\n",
            "stemming\n",
            "and\n",
            "lemmatization\n",
            "are\n",
            "compared\n",
            "to\n",
            "highlight\n",
            "their\n",
            "difference\n",
            ",\n",
            "showing\n",
            "that\n",
            "stemming\n",
            "may\n",
            "distort\n",
            "medical\n",
            "term\n",
            "while\n",
            "lemmatization\n",
            "preserve\n",
            "semantic\n",
            "and\n",
            "clinical\n",
            "meaning\n",
            ".\n",
            "This\n",
            "comparison\n",
            "lead\n",
            "to\n",
            "a\n",
            "discussion\n",
            "emphasizing\n",
            "why\n",
            "lemmatization\n",
            "is\n",
            "critical\n",
            "in\n",
            "healthcare\n",
            "NLP\n",
            ",\n",
            "a\n",
            "accurate\n",
            "terminology\n",
            "is\n",
            "essential\n",
            "for\n",
            "task\n",
            "such\n",
            "a\n",
            "clinical\n",
            "text\n",
            "analysis\n",
            ",\n",
            "information\n",
            "retrieval\n",
            ",\n",
            "medical\n",
            "coding\n",
            ",\n",
            "and\n",
            "decision\n",
            "support\n",
            "system\n",
            ".\n",
            "The\n",
            "complete\n",
            "workflow\n",
            "is\n",
            "documented\n",
            "in\n",
            "a\n",
            "Google\n",
            "Colab\n",
            "notebook\n",
            "with\n",
            "proper\n",
            "heading\n",
            "and\n",
            "a\n",
            "discussion\n",
            "section\n",
            "at\n",
            "the\n",
            "end\n",
            ",\n",
            "and\n",
            "the\n",
            "final\n",
            "notebook\n",
            "is\n",
            "submitted\n",
            "a\n",
            "a\n",
            "PDF\n",
            ".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W_dW_JsZkUo0",
        "outputId": "1b1d7f76-6e35-4898-8fdd-9386c18d7236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L_AUCtMykcUG",
        "outputId": "4cc1dc6b-32e6-4abe-cc4c-6c5398d7a979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer,RegexpStemmer,WordNetLemmatizer\n",
        "poter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer('english')\n",
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\"railroad\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",\"Regexp Stemmer\",\"WordNet Lemmatizer\"))\n",
        "print(\"-\"*160)\n",
        "for word in word_list:\n",
        "      print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word, poter.stem(word), snowball.stem(word), lancaster.stem(word), regexp.stem(word), lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ays2Ctfwke4c",
        "outputId": "9a1cb6b0-74f9-4acc-e290-834508a4453f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNet Lemmatizer                                \n",
            "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "friend              friend              friend              friend                        friend                                  friend                                            \n",
            "friendship          friendship          friendship          friend                        friendship                              friendship                                        \n",
            "friends             friend              friend              friend                        friend                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        friendship                              friendship                                        \n",
            "stabil              stabil              stabil              stabl                         stabil                                  stabil                                            \n",
            "destabilize         destabil            destabil            dest                          destabiliz                              destabilize                                       \n",
            "misunderstanding    misunderstand       misunderstand       misunderstand                 misunderstand                           misunderstanding                                  \n",
            "railroad            railroad            railroad            railroad                      railroad                                railroad                                          \n"
          ]
        }
      ]
    }
  ]
}